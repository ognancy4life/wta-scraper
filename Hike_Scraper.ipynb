{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Notebook file for testing and playing around with methods, have fun! ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages.\n",
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "import urllib3\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Requests & BeautifulSoup, pass a URL to this method and it will return the URL's HTML code as a list of lines.\n",
    "def get_html_rows(url):\n",
    "    r = requests.get(url, verify=False) \n",
    "    s = BeautifulSoup(r.content, 'html5lib') \n",
    "    html = s.prettify()\n",
    "    return html.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking 'https://www.wta.org/go-hiking/hikes' as a parameter,\n",
    "# this method will find all links to pages consisting of a list of hikes and, return all links as a list using recursion.\n",
    "# Note, this method does not include 'https://www.wta.org/go-outside/hikes' in the returned list.\n",
    "def get_hikes_list_page_urls(url, last_page=None):\n",
    "    \n",
    "    html_rows = get_html_rows(url)\n",
    "    \n",
    "    check = False\n",
    "    exit = False\n",
    "    active_page = 0\n",
    "    index_start = 0\n",
    "    index_end = 0\n",
    "\n",
    "    itr = -1\n",
    "    for row in html_rows:\n",
    "        itr += 1\n",
    "\n",
    "        if '\"active\"' in row:\n",
    "            index_start = html_rows.index(row)\n",
    "            active_page = int(html_rows[itr + 2].lstrip())\n",
    "\n",
    "        if '\"last\"' in row:\n",
    "            index_end = html_rows.index(row)\n",
    "            last_page = int(html_rows[itr + 2].lstrip())\n",
    "            check = True\n",
    "            break           \n",
    "        elif check == False and '\"next\"' in row:\n",
    "            index_end = html_rows.index(row)\n",
    "            last_page = int(html_rows[itr - 3].lstrip())\n",
    "            check = True\n",
    "            exit = True\n",
    "            break        \n",
    "        elif check == False and active_page == last_page:\n",
    "            return\n",
    "            \n",
    "    rows_range = html_rows[index_start : index_end]\n",
    "    pages_found = [item[item.find('https') : item.find('\">')] for item in rows_range if 'www.wta.org' in item]\n",
    "    next_page = pages_found[0]\n",
    "    \n",
    "    if exit == True:\n",
    "        return pages_found\n",
    "    else:\n",
    "        return list(set().union(pages_found, get_hikes_list_page_urls(next_page, last_page)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a list of links consisting of WTA's pages, that houses their lists of hikes, as a parameter,\n",
    "# this method will return a list of links to all hikes found on wta.org.    \n",
    "def get_individual_hike_urls(hikes_list_page_urls):\n",
    "    \n",
    "    hike_urls_list = []\n",
    "    \n",
    "    for url in hikes_list_page_urls:\n",
    "        html_rows = get_html_rows(url)\n",
    "        \n",
    "        for row in html_rows:\n",
    "            \n",
    "            if \"listitem-title\" in row:\n",
    "                hike_url = row[row.find('https') : row.find('\" title=')]                \n",
    "                hike_urls_list.append(hike_url)\n",
    "                \n",
    "    return hike_urls_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a list of individual hike links as a parameter,\n",
    "# this method will reutrn specific information for each hike in the format of a DataFrame.\n",
    "def get_hike_info(hike_urls):\n",
    "\n",
    "    titles = []\n",
    "    regions = []\n",
    "    distances = []\n",
    "    dist_types = []\n",
    "    gains = []\n",
    "    highests = []\n",
    "    ratings = []\n",
    "    rating_counts = []\n",
    "    latitudes = []\n",
    "    longitudes = []\n",
    "    report_counts = []\n",
    "    report_dates = []\n",
    "    hike_links = []\n",
    "\n",
    "    rownum = 1\n",
    "    for url in hike_urls:\n",
    "        hike_html_rows = get_html_rows(url)\n",
    "\n",
    "        itr1 = -1\n",
    "        for row in hike_html_rows:\n",
    "            itr1 += 1\n",
    "\n",
    "            if '\"documentFirstHeading\"' in row:\n",
    "                hike_title = hike_html_rows[itr1 + 1].lstrip()\n",
    "                titles.append(hike_title)\n",
    "\n",
    "            if '\"hike-region\"' in row:\n",
    "                hike_region = hike_html_rows[itr1 + 3].lstrip()\n",
    "                regions.append(hike_region)\n",
    "\n",
    "            if '\"distance\"' in row:\n",
    "                hike_distance_string = hike_html_rows[itr1 + 2].lstrip()\n",
    "                hike_distance = float(hike_distance_string[ : hike_distance_string.find(' mile')])\n",
    "                if ',' in hike_distance_string:\n",
    "                    hike_distance_type = hike_distance_string[hike_distance_string.find(', ') + 2 : ]\n",
    "                elif 'of trails' in hike_distance_string:\n",
    "                    hike_distance_type = hike_distance_string[hike_distance_string.find('of trails') + 3 : ]\n",
    "                else:\n",
    "                    hike_distance = 'ERROR'\n",
    "                distances.append(hike_distance)\n",
    "                dist_types.append(hike_distance_type)\n",
    "\n",
    "            if 'Gain:' in row:\n",
    "                hike_gain = float(hike_html_rows[itr1 + 2].lstrip())\n",
    "                gains.append(hike_gain)\n",
    "\n",
    "            if 'Highest Point:' in row:\n",
    "                hike_highest = float(hike_html_rows[itr1 + 2].lstrip())\n",
    "                highests.append(hike_highest)\n",
    "\n",
    "            if '\"current-rating\"' in row:\n",
    "                rating_string = hike_html_rows[itr1 + 1].lstrip()\n",
    "                hike_rating = float(rating_string[ : rating_string.find(' out of')])\n",
    "                ratings.append(hike_rating)\n",
    "\n",
    "            if '\"rating-count\"' in row:\n",
    "                rating_count_string = hike_html_rows[itr1 + 1].lstrip()\n",
    "                rating_count = int(rating_count_string[rating_count_string.find('(') + 1 : rating_count_string.find(' vote')])\n",
    "                rating_counts.append(rating_count)\n",
    "                \n",
    "            if '<script type=\"application/ld+json\">' in row:\n",
    "                json_string = hike_html_rows[itr1 + 1].lstrip()\n",
    "                hike_json = json.loads(json_string)\n",
    "                try:\n",
    "                    latitude = hike_json['geo']['latitude']\n",
    "                    longitude = hike_json['geo']['longitude']\n",
    "                    latitudes.append(latitude)\n",
    "                    longitudes.append(longitude)\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                \n",
    "        if len(titles) != rownum:\n",
    "            titles.append(None)\n",
    "\n",
    "        if len(regions) != rownum:\n",
    "            regions.append(None)\n",
    "\n",
    "        if len(distances) != rownum:\n",
    "            distances.append(None)\n",
    "\n",
    "        if len(dist_types) != rownum:\n",
    "            dist_types.append(None)\n",
    "\n",
    "        if len(gains) != rownum:\n",
    "            gains.append(None)\n",
    "\n",
    "        if len(highests) != rownum:\n",
    "            highests.append(None)\n",
    "\n",
    "        if len(ratings) != rownum:\n",
    "            ratings.append(None)\n",
    "\n",
    "        if len(rating_counts) != rownum:\n",
    "            rating_counts.append(None)\n",
    "            \n",
    "        if len(latitudes) != rownum:\n",
    "            latitudes.append(None)\n",
    "\n",
    "        if len(longitudes) != rownum:\n",
    "            longitudes.append(None)\n",
    "        \n",
    "\n",
    "\n",
    "        report_link = url + '/@@related_tripreport_listing'\n",
    "        report_html_rows = get_html_rows(report_link)\n",
    "        report_date_list = []\n",
    "\n",
    "        itr2 = -1\n",
    "        for row in report_html_rows:\n",
    "            itr2 += 1\n",
    "\n",
    "            if '\"count-data\"' in row:\n",
    "                report_count = int(report_html_rows[itr2 + 1].lstrip())\n",
    "                report_counts.append(report_count)\n",
    "\n",
    "            if '\"elapsed-time\"' in row:\n",
    "                report_date = datetime.strptime(row[row.find('title=\"') + 7 : row.find('\">')], '%b %d, %Y')\n",
    "                report_date_list.append(report_date)\n",
    "\n",
    "        if len(report_counts) != rownum:\n",
    "            report_counts.append(None)\n",
    "\n",
    "        if len(report_date_list) != 0:\n",
    "            report_dates.append(report_date_list[0])\n",
    "        elif len(report_dates) != rownum:\n",
    "            report_dates.append(None)\n",
    "\n",
    "        hike_links.append(url)\n",
    "        \n",
    "        print(str(rownum) + ' Hikes loaded...')\n",
    "        rownum += 1\n",
    "        \n",
    "    print('Finished loading hikes!\\n' + str(rownum - 1) + ' Hikes successfully loaded.') \n",
    "    print('titles: ', len(titles), ' entries')\n",
    "    print('regions: ', len(regions), ' entries')\n",
    "    print('distances: ', len(distances), ' entries')\n",
    "    print('dist_types: ', len(dist_types), ' entries')\n",
    "    print('gains: ', len(gains), ' entries')\n",
    "    print('highests: ', len(highests), ' entries')\n",
    "    print('ratings: ', len(ratings), ' entries')\n",
    "    print('rating_counts: ', len(rating_counts), ' entries')\n",
    "    print('latitudes: ', len(latitudes), 'Entries')\n",
    "    print('longitudes: ', len(longitudes), 'Entries')\n",
    "    print('report_dates: ', len(report_dates), ' entries')\n",
    "    print('report_counts: ', len(report_counts), ' entries')\n",
    "    print('hike_links: ', len(hike_links), ' entries')\n",
    "    \n",
    "    return pd.DataFrame({'TITLE': titles, 'REGION': regions, 'DISTANCE': distances,\n",
    "                         'DIST_TYPE': dist_types, 'GAIN': gains, 'HIGHEST': highests,\n",
    "                         'RATING': ratings, 'RATING_COUNT': rating_counts, \n",
    "                         'LATITUDE': latitudes, 'LONGITUDE': longitudes, \n",
    "                         'REPORT_DATE': report_dates, 'REPORT_COUNT': report_counts, \n",
    "                         'URL': hike_urls2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all hike page links.\n",
    "all_hikes_list_pages = list(set().union(get_hikes_list_page_urls('https://www.wta.org/go-outside/hikes'), ['https://www.wta.org/go-outside/hikes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all individual hike links.\n",
    "all_individual_hikes = get_individual_hike_urls(all_hikes_list_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all hike data, initialize to DataFrame.\n",
    "wta_hikes_df = get_hike_info(all_individual_hikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to csv file.\n",
    "curr_date = datetime.now().date()\n",
    "wta_hikes_df.to_csv('YOUR_FILE_LOCATION'.format(curr_date), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
