{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Notebook file for testing and playing around with methods, have fun! ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages.\n",
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "import urllib3\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Requests & BeautifulSoup, pass a URL to this method and it will return the URL's HTML code as a list of lines.\n",
    "def get_html_rows(url):\n",
    "    r = requests.get(url, verify=False) \n",
    "    s = BeautifulSoup(r.content, 'html5lib') \n",
    "    html = s.prettify()\n",
    "    return html.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking 'https://www.wta.org/go-hiking/hikes' as a parameter,\n",
    "# this method will find all links to pages consisting of a list of hikes and, return all links as a list using recursion.\n",
    "# Note, this method does not include 'https://www.wta.org/go-outside/hikes' in the returned list.\n",
    "def get_hike_pages(url, last_page = None):\n",
    "    \n",
    "    rows_list = get_html_rows(url)\n",
    "    \n",
    "    check = False\n",
    "    exit = False\n",
    "    active_page = 0\n",
    "    index_start = 0\n",
    "    index_end = 0\n",
    "\n",
    "    itr = -1\n",
    "    for row in rows_list:\n",
    "        itr += 1\n",
    "\n",
    "        if '\"active\"' in row:\n",
    "            index_start = rows_list.index(row)\n",
    "            active_page = int(rows_list[itr + 2].lstrip())\n",
    "\n",
    "        if '\"last\"' in row:\n",
    "            index_end = rows_list.index(row)\n",
    "            last_page = int(rows_list[itr + 2].lstrip())\n",
    "            check = True\n",
    "            break           \n",
    "        elif check == False and '\"next\"' in row:\n",
    "            index_end = rows_list.index(row)\n",
    "            last_page = int(rows_list[itr - 3].lstrip())\n",
    "            check = True\n",
    "            exit = True\n",
    "            break        \n",
    "        elif check == False and active_page == last_page:\n",
    "            return\n",
    "            \n",
    "    rows_range = rows_list[index_start : index_end]\n",
    "    pages_found = [item[item.find('https') : item.find('\">')] for item in rows_range if 'www.wta.org' in item]\n",
    "    next_page = pages_found[0]\n",
    "    \n",
    "    if exit == True:\n",
    "        return pages_found\n",
    "    else:\n",
    "        return list(set().union(pages_found, get_hike_pages(next_page, last_page)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a list of links consisting of WTA's pages, that houses their lists of hikes, as a parameter,\n",
    "# this method will return a list of links to all hikes found on wta.org.    \n",
    "def get_hikes(hike_page_links):\n",
    "    \n",
    "    hike_links_list = []\n",
    "    \n",
    "    for link in hike_page_links:\n",
    "        rows_list = get_html_rows(link)\n",
    "        \n",
    "        for row in rows_list:\n",
    "            \n",
    "            if \"listitem-title\" in row:\n",
    "                hike_link = row[row.find('https') : row.find('\" title=')]                \n",
    "                hike_links_list.append(hike_link)\n",
    "                \n",
    "    return hike_links_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a list of individual hike links as a parameter,\n",
    "# this method will reutrn specific information for each hike in the format of a DataFrame.\n",
    "def get_hike_info(hike_urls):\n",
    "\n",
    "    titles = []\n",
    "    regions = []\n",
    "    distances =[]\n",
    "    dist_types =[]\n",
    "    gains = []\n",
    "    highests = []\n",
    "    ratings = []\n",
    "    rating_counts =[]\n",
    "    report_counts =[]\n",
    "    report_dates = []\n",
    "    hike_links =[]\n",
    "\n",
    "    rownum = 1\n",
    "    for link in hike_urls:\n",
    "        hike_rows_list = get_html_rows(link)\n",
    "\n",
    "        itr1 = -1\n",
    "        for row1 in hike_rows_list:\n",
    "            itr1 += 1\n",
    "\n",
    "            if '\"documentFirstHeading\"' in row1:\n",
    "                hike_title = hike_rows_list[itr1 + 1].lstrip()\n",
    "                titles.append(hike_title)\n",
    "\n",
    "            if '\"hike-region\"' in row1:\n",
    "                hike_region = hike_rows_list[itr1 + 3].lstrip()\n",
    "                regions.append(hike_region)\n",
    "\n",
    "            if '\"distance\"' in row1:\n",
    "                hike_distance_string = hike_rows_list[itr1 + 2].lstrip()\n",
    "                hike_distance = float(hike_distance_string[ : hike_distance_string.find(' mile')])\n",
    "                if ',' in hike_distance_string:\n",
    "                    hike_distance_type = hike_distance_string[hike_distance_string.find(', ') + 2 : ]\n",
    "                elif 'of trails' in hike_distance_string:\n",
    "                    hike_distance_type = hike_distance_string[hike_distance_string.find('of trails') + 3 : ]\n",
    "                else:\n",
    "                    hike_distance = 'ERROR'\n",
    "                distances.append(hike_distance)\n",
    "                dist_types.append(hike_distance_type)\n",
    "\n",
    "            if 'Gain:' in row1:\n",
    "                hike_gain = float(hike_rows_list[itr1 + 2].lstrip())\n",
    "                gains.append(hike_gain)\n",
    "\n",
    "            if 'Highest Point:' in row1:\n",
    "                hike_highest = float(hike_rows_list[itr1 + 2].lstrip())\n",
    "                highests.append(hike_highest)\n",
    "\n",
    "            if '\"current-rating\"' in row1:\n",
    "                rating_string = hike_rows_list[itr1 + 1].lstrip()\n",
    "                hike_rating = float(rating_string[ : rating_string.find(' out of')])\n",
    "                ratings.append(hike_rating)\n",
    "\n",
    "            if '\"rating-count\"' in row1:\n",
    "                rating_count_string = hike_rows_list[itr1 + 1].lstrip()\n",
    "                rating_count = int(rating_count_string[rating_count_string.find('(') + 1 : rating_count_string.find(' vote')])\n",
    "                rating_counts.append(rating_count)\n",
    "\n",
    "        if len(titles) != rownum:\n",
    "            titles.append(None)\n",
    "\n",
    "        if len(regions) != rownum:\n",
    "            regions.append(None)\n",
    "\n",
    "        if len(distances) != rownum:\n",
    "            distances.append(None)\n",
    "\n",
    "        if len(dist_types) != rownum:\n",
    "            dist_types.append(None)\n",
    "\n",
    "        if len(gains) != rownum:\n",
    "            gains.append(None)\n",
    "\n",
    "        if len(highests) != rownum:\n",
    "            highests.append(None)\n",
    "\n",
    "        if len(ratings) != rownum:\n",
    "            ratings.append(None)\n",
    "\n",
    "        if len(rating_counts) != rownum:\n",
    "            rating_counts.append(None)\n",
    "\n",
    "\n",
    "        report_link = link + '/@@related_tripreport_listing'\n",
    "        report_rows_list = get_html_rows(report_link)\n",
    "        report_date_list = []\n",
    "\n",
    "        itr2 = -1\n",
    "        for row2 in report_rows_list:\n",
    "            itr2 += 1\n",
    "\n",
    "            if '\"count-data\"' in row2:\n",
    "                report_count = int(report_rows_list[itr2 + 1].lstrip())\n",
    "                report_counts.append(report_count)\n",
    "\n",
    "            if '\"elapsed-time\"' in row2:\n",
    "                report_date = datetime.strptime(row2[row2.find('title=\"') + 7 : row2.find('\">')], '%b %d, %Y')\n",
    "                report_date_list.append(report_date)\n",
    "\n",
    "        if len(report_counts) != rownum:\n",
    "            report_counts.append(None)\n",
    "\n",
    "        if len(report_date_list) != 0:\n",
    "            report_dates.append(report_date_list[0])\n",
    "        elif len(report_dates) != rownum:\n",
    "            report_dates.append(None)\n",
    "\n",
    "        hike_links.append(link)\n",
    "        \n",
    "        print(str(rownum) + ' Hikes loaded...')\n",
    "        rownum += 1\n",
    "        \n",
    "    print('Finished loading hikes!\\n' + rownum + ' Hikes successfully loaded.') \n",
    "    print('titles: ', len(titles), ' entries')\n",
    "    print('regions: ', len(regions), ' entries')\n",
    "    print('distances: ', len(distances), ' entries')\n",
    "    print('dist_types: ', len(dist_types), ' entries')\n",
    "    print('gains: ', len(gains), ' entries')\n",
    "    print('highests: ', len(highests), ' entries')\n",
    "    print('ratings: ', len(ratings), ' entries')\n",
    "    print('rating_counts: ', len(rating_counts), ' entries')\n",
    "    print('report_dates: ', len(report_dates), ' entries')\n",
    "    print('report_counts: ', len(report_counts), ' entries')\n",
    "    print('hike_links: ', len(hike_links), ' entries')\n",
    "    \n",
    "    return pd.DataFrame({'TITLE': titles, 'REGION': regions, 'DISTANCE': distances, 'DIST_TYPE': dist_types,\n",
    "                        'GAIN': gains, 'HIGHEST': highests, 'RATING': ratings, 'RATING_COUNT': rating_counts,\n",
    "                        'REPORT_DATE': report_dates, 'REPORT_COUNT': report_counts, 'LINK': hike_links})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all hike page links.\n",
    "all_hike_page_links = list(set().union(get_hike_pages('https://www.wta.org/go-outside/hikes'), ['https://www.wta.org/go-outside/hikes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all individual hike links.\n",
    "all_hike_links = get_hikes(all_hike_page_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all hike data, initialize to DataFrame.\n",
    "wta_hikes = get_hike_info(all_hike_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to csv file.\n",
    "curr_date = datetime.now().date()\n",
    "wta_hikes.to_csv('YOUR_FILE_LOCATION'.format(curr_date), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
